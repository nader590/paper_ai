import streamlit as st
from transformers import MT5ForConditionalGeneration, MT5Tokenizer, pipeline
import PyPDF2

# ================= ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ =================
@st.cache_resource
def load_model():
    MODEL_NAME = "google/mt5-small"
    tokenizer = MT5Tokenizer.from_pretrained(MODEL_NAME, legacy=False)  # Ø¹Ø´Ø§Ù† Ø§Ù„ØªØ­Ø°ÙŠØ± ÙŠØ®ØªÙÙŠ
    model = MT5ForConditionalGeneration.from_pretrained(MODEL_NAME)
    generator = pipeline("text2text-generation", model=model, tokenizer=tokenizer)
    return generator

generator = load_model()

# ================= Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© =================
def extract_text_from_pdf(file) -> str:
    pdf_reader = PyPDF2.PdfReader(file)
    text = ""
    for page in pdf_reader.pages:
        if page.extract_text():
            text += page.extract_text() + "\n"
    return text.strip()

def ask_model(prompt: str, max_new_tokens=500):
    outputs = generator(
        prompt,
        max_new_tokens=max_new_tokens,
        do_sample=True,
        temperature=0.7
    )
    return outputs[0]["generated_text"]

# ================= Streamlit App =================
st.title("ğŸ“„ AI Paper Assistant (Arabic & English)")

uploaded_file = st.file_uploader("Ø§Ø±ÙØ¹ ÙˆØ±Ù‚Ø© PDF", type=["pdf"])

if uploaded_file:
    st.success("âœ… ØªÙ… Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù Ø¨Ù†Ø¬Ø§Ø­")

    text = extract_text_from_pdf(uploaded_file)
    st.subheader("ğŸ“‘ Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬ Ù…Ù† Ø§Ù„ÙˆØ±Ù‚Ø©")
    st.text_area("Extracted Text", text[:3000] + ("..." if len(text) > 3000 else ""), height=200)

    lang = st.radio("ğŸŒ Ø§Ø®ØªØ± Ø§Ù„Ù„ØºØ©", ["Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©", "English"])

    if st.button("ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙˆØ±Ù‚Ø©"):
        with st.spinner("â³ Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„..."):

            if lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©":
                classify_prompt = f"ØµÙ†Ù‘Ù Ù‡Ø°Ù‡ Ø§Ù„ÙˆØ±Ù‚Ø© Ø§Ù„Ø¹Ù„Ù…ÙŠØ© Ø­Ø³Ø¨ Ù…Ø¬Ø§Ù„Ù‡Ø§ ÙˆÙ†ÙˆØ¹Ù‡Ø§:\n{text[:1500]}"
                summary_prompt = f"Ù„Ø®Ù‘Øµ Ù‡Ø°Ù‡ Ø§Ù„ÙˆØ±Ù‚Ø© Ø§Ù„Ø¹Ù„Ù…ÙŠØ© Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙÙŠ Ù†Ù‚Ø§Ø· ÙˆØ§Ø¶Ø­Ø©:\n{text[:2000]}"
            else:
                classify_prompt = f"Classify this research paper by its field and type:\n{text[:1500]}"
                summary_prompt = f"Summarize this research paper in clear points in English:\n{text[:2000]}"

            classification = ask_model(classify_prompt, max_new_tokens=200)
            summary = ask_model(summary_prompt, max_new_tokens=400)

        st.subheader("ğŸ“Œ Ø§Ù„ØªØµÙ†ÙŠÙ / Classification")
        st.write(classification)

        st.subheader("ğŸ“ Ø§Ù„Ù…Ù„Ø®Øµ / Summary")
        st.write(summary)

    st.subheader("â“ Ø§Ø³Ø£Ù„ Ø³Ø¤Ø§Ù„ Ø¹Ù† Ø§Ù„ÙˆØ±Ù‚Ø©")
    question = st.text_input("Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ / Type your question")
    if st.button("Ø¥Ø¬Ø§Ø¨Ø© / Answer"):
        if lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©":
            qa_prompt = f"Ø§Ù„Ù†Øµ Ø§Ù„ØªØ§Ù„ÙŠ Ù…Ù† ÙˆØ±Ù‚Ø© Ø¹Ù„Ù…ÙŠØ©:\n{text[:1500]}\n\nØ§Ù„Ø³Ø¤Ø§Ù„: {question}\nØ§Ù„Ø¥Ø¬Ø§Ø¨Ø©:"
        else:
            qa_prompt = f"The following text is from a research paper:\n{text[:1500]}\n\nQuestion: {question}\nAnswer:"
        
        answer = ask_model(qa_prompt, max_new_tokens=300)
        st.subheader("ğŸ’¡ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© / Answer")
        st.write(answer)
