import streamlit as st
from transformers import MT5ForConditionalGeneration, MT5Tokenizer, pipeline
import PyPDF2

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ù„ØºØ§Øª
MODEL_NAME = "google/mt5-small"
tokenizer = MT5Tokenizer.from_pretrained(MODEL_NAME)
model = MT5ForConditionalGeneration.from_pretrained(MODEL_NAME)
generator = pipeline("text2text-generation", model=model, tokenizer=tokenizer)

# Ø¯Ø§Ù„Ø© Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† PDF
def extract_text_from_pdf(file) -> str:
    pdf_reader = PyPDF2.PdfReader(file)
    text = ""
    for page in pdf_reader.pages:
        if page.extract_text():
            text += page.extract_text() + "\n"
    return text.strip()

# Ø¯Ø§Ù„Ø© Ù„Ù„ØªÙˆÙ„ÙŠØ¯ Ù…Ù† Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„
def ask_model(prompt: str, max_new_tokens=500):
    outputs = generator(
        prompt,
        max_new_tokens=max_new_tokens,
        do_sample=True,
        temperature=0.7
    )
    return outputs[0]["generated_text"]

# ÙˆØ§Ø¬Ù‡Ø© Streamlit
st.title("ğŸ“„ Ø£Ø¯Ø§Ø© ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£ÙˆØ±Ø§Ù‚ Ø§Ù„Ø¹Ù„Ù…ÙŠØ©")

uploaded_file = st.file_uploader("ğŸ“¥ Ø§Ø±ÙØ¹ ÙˆØ±Ù‚Ø© PDF", type=["pdf"])

if uploaded_file:
    text = extract_text_from_pdf(uploaded_file)

    st.subheader("ğŸ”  Ø§Ø®ØªØ± Ù„ØºØ© Ø§Ù„ØªÙ„Ø®ÙŠØµ")
    lang = st.selectbox("Ø§Ù„Ù„ØºØ©", ["Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©", "English"])

    if lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©":
        classify_prompt = f"ØµÙ†Ù‘Ù Ù‡Ø°Ù‡ Ø§Ù„ÙˆØ±Ù‚Ø© Ø§Ù„Ø¹Ù„Ù…ÙŠØ© Ø­Ø³Ø¨ Ù…Ø¬Ø§Ù„Ù‡Ø§ ÙˆÙ†ÙˆØ¹Ù‡Ø§:\n{text[:1500]}"
        summary_prompt = f"Ù„Ø®Ù‘Øµ Ù‡Ø°Ù‡ Ø§Ù„ÙˆØ±Ù‚Ø© Ø§Ù„Ø¹Ù„Ù…ÙŠØ© Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙÙŠ Ù†Ù‚Ø§Ø· ÙˆØ§Ø¶Ø­Ø©:\n{text[:4000]}"
    else:
        classify_prompt = f"Classify this scientific paper by its field and type:\n{text[:1500]}"
        summary_prompt = f"Summarize this scientific paper in clear bullet points in English:\n{text[:4000]}"

    if st.button("ğŸš€ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙˆØ±Ù‚Ø©"):
        classification = ask_model(classify_prompt, max_new_tokens=200)
        summary = ask_model(summary_prompt, max_new_tokens=400)

        st.write("### ğŸ·ï¸ Ø§Ù„ØªØµÙ†ÙŠÙ / Classification")
        st.success(classification)

        st.write("### ğŸ“Œ Ø§Ù„Ù…Ù„Ø®Øµ / Summary")
        st.info(summary)

        st.write("### ğŸ“– Ù†Øµ Ù…Ù† Ø§Ù„ÙˆØ±Ù‚Ø© (Ù…Ù‚ØªØ·Ù)")
        st.text(text[:1000])

# Ù‚Ø³Ù… Ù„Ù„Ø£Ø³Ø¦Ù„Ø©
st.subheader("â“ Ø§Ø³Ø£Ù„ Ø¹Ù† Ø§Ù„ÙˆØ±Ù‚Ø©")
question = st.text_input("Ø£Ø¯Ø®Ù„ Ø³Ø¤Ø§Ù„Ùƒ Ù‡Ù†Ø§")
context = st.text_area("Ø§Ù†Ø³Ø® Ø§Ù„Ù†Øµ (Ø£Ùˆ Ø¬Ø²Ø¡ Ù…Ù† Ø§Ù„ÙˆØ±Ù‚Ø©) Ù‡Ù†Ø§")

if st.button("ğŸ’¡ Ø§Ø­ØµÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©"):
    if question and context:
        qa_prompt = f"Ø§Ù„Ù†Øµ Ø§Ù„ØªØ§Ù„ÙŠ Ù…Ù† ÙˆØ±Ù‚Ø© Ø¹Ù„Ù…ÙŠØ©:\n{context}\n\nØ§Ù„Ø³Ø¤Ø§Ù„: {question}\nØ§Ù„Ø¥Ø¬Ø§Ø¨Ø©:"
        answer = ask_model(qa_prompt, max_new_tokens=300)
        st.success(answer)
    else:
        st.warning("âš ï¸ Ø£Ø¯Ø®Ù„ Ø³Ø¤Ø§Ù„Ø§Ù‹ ÙˆÙ†ØµØ§Ù‹ Ø£ÙˆÙ„Ø§Ù‹")
